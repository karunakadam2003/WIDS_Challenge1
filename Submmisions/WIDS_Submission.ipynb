{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_2yodmDoyZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "TBTS2yyENq23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "train = pd.read_csv(\"/kaggle/input/widsdatathon2024-challenge1/training.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/widsdatathon2024-challenge1/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/kaggle/input/widsdatathon2024-challenge1/sample_submission.csv\")\n"
      ],
      "metadata": {
        "id": "_Yx9EYdlNb-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "T5vTf0_cNoo4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGxmJiZgNwmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA & Feature Engineering"
      ],
      "metadata": {
        "id": "Lz2BBMJZkTrv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nml26t6kTTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "jAfF4yJHkfTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "XGBOOST"
      ],
      "metadata": {
        "id": "VuH6Tb3hqZ2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('final_rounded.csv')\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop(['DiagPeriodL90D'], axis=1)\n",
        "y = df['DiagPeriodL90D']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a decision tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions from the decision tree model\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "\n",
        "# Train an XGBoost model\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "print(f'Number of labels: {len(y_train)}')\n",
        "print(f'Number of rows in training data: {X_train_stacked.shape[0]}')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions from the XGBoost model\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Combine predictions (using a simple average)\n",
        "hybrid_predictions = (dt_predictions + xgb_predictions) / 2\n",
        "\n",
        "# Convert hybrid predictions to binary (0 or 1)\n",
        "hybrid_predictions = (hybrid_predictions > 0.5).astype(int)\n",
        "\n",
        "# Evaluate accuracy of the hybrid model\n",
        "accuracy = accuracy_score(y_test, hybrid_predictions)\n",
        "print(f'Hybrid Model Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBHsSmy3rIa4",
        "outputId": "038f896e-3eeb-4fcb-999b-5b651d052729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 10324\n",
            "Number of rows in training data: 12416\n",
            "Hybrid Model Accuracy: 0.6665375677769171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier"
      ],
      "metadata": {
        "id": "wgWAdTVpwAGu"
      }
    },
    {
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing sets\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_dt = accuracy_score(y_test, dt_predictions)\n",
        "print(f'Decision Tree Accuracy: {accuracy_dt}')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_eYZSOeRtnZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14be51a3-7d00-4ca2-f50c-d587631d9e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.6537567776917118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB"
      ],
      "metadata": {
        "id": "_UtBU3TdwIeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize XGBoost classifier with specified parameters\n",
        "xgb_model = XGBClassifier(\n",
        "    random_state=42,\n",
        "    booster='gbtree',\n",
        "    n_estimators=18,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.2,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=1,\n",
        "    gamma=0,\n",
        "    min_child_weight=1,\n",
        "    subsample=1,\n",
        "    colsample_bytree=1,\n",
        "    missing=np.nan\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions on the test set\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_xgb = accuracy_score(y_test, xgb_predictions)\n",
        "print(f'XGBoost Accuracy: {accuracy_xgb}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDzOQGP9wLBm",
        "outputId": "3b3484dc-29e1-427a-e159-aa9a4f8df195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.7587141750580945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize Gradient Boosting classifier with specified parameters\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_samples_leaf=1\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions on the test set\n",
        "gb_predictions = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_gb = accuracy_score(y_test, gb_predictions)\n",
        "print(f'Gradient Boosting Accuracy: {accuracy_gb}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Gydbrbxuj6",
        "outputId": "1c9b53ac-3b1f-4ab2-f80e-cc51b4106f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Accuracy: 0.7598760650658405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGBM"
      ],
      "metadata": {
        "id": "7nBIMNquyLE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import re\n",
        "\n",
        "# Remove special characters from feature names\n",
        "X_train.columns = [re.sub(r'[^\\w\\s]', '', col) for col in X_train.columns]\n",
        "\n",
        "# Initialize LightGBM classifier with specified parameters\n",
        "lgbm_model = LGBMClassifier(\n",
        "    random_state=42,\n",
        "    n_estimators=9,\n",
        "    max_leaves=31,\n",
        "    learning_rate=0.2,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=0,\n",
        "    min_split_gain=0,\n",
        "    min_child_weight=0.001,\n",
        "    subsample=1,\n",
        "    colsample_bytree=0.7\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions on the test set\n",
        "lgbm_predictions = lgbm_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_lgbm = accuracy_score(y_test, lgbm_predictions)\n",
        "print(f'LightGBM Accuracy: {accuracy_lgbm}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGfPfAe5yKoH",
        "outputId": "9275d096-cd62-431a-c747-cb7539700268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] num_leaves is set=31, max_leaves=31 will be ignored. Current value: num_leaves=31\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] num_leaves is set=31, max_leaves=31 will be ignored. Current value: num_leaves=31\n",
            "[LightGBM] [Info] Number of positive: 6443, number of negative: 3881\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008846 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 17597\n",
            "[LightGBM] [Info] Number of data points in the train set: 10324, number of used features: 84\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624080 -> initscore=0.506901\n",
            "[LightGBM] [Info] Start training from score 0.506901\n",
            "[LightGBM] [Warning] num_leaves is set=31, max_leaves=31 will be ignored. Current value: num_leaves=31\n",
            "LightGBM Accuracy: 0.7618125484120837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "0Z39729bkjcN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uKdcvs_kqHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HyperParameter Tunning"
      ],
      "metadata": {
        "id": "F4OZM_m2kq9X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJTfohuYkqpM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}